{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Ollama",
  "description": "Interact with Ollama AI models",
  "x-n8n-node-type": "ollama",
  "x-n8n-version": 1,
  "x-n8n-group": [
    "transform"
  ],
  "type": "object",
  "properties": {
    "resource": {
      "x-title": "Resource",
      "default": "text",
      "type": "string",
      "enum": [
        "image",
        "text"
      ],
      "x-enumNames": [
        "Image",
        "Text"
      ]
    },
    "operation": {
      "x-title": "Operation",
      "default": "message",
      "x-displayOptions": {
        "show": {
          "resource": [
            "text"
          ]
        }
      },
      "type": "string",
      "enum": [
        "message"
      ],
      "x-enumNames": [
        "Message a Model"
      ],
      "x-enumDescriptions": [
        "Send a message to Ollama model"
      ]
    },
    "modelId": {
      "x-title": "Model",
      "default": {
        "mode": "list",
        "value": ""
      },
      "x-displayOptions": {
        "show": {
          "operation": [
            "message"
          ],
          "resource": [
            "text"
          ]
        }
      },
      "x-required": true,
      "type": "object",
      "properties": {
        "__rl": {
          "type": "boolean",
          "const": true
        },
        "mode": {
          "type": "string",
          "enum": [
            "list",
            "id"
          ]
        },
        "value": {
          "type": "string"
        }
      },
      "required": [
        "mode",
        "value"
      ],
      "x-modes": [
        {
          "name": "list",
          "displayName": "From List",
          "type": "list"
        },
        {
          "name": "id",
          "displayName": "ID",
          "type": "string"
        }
      ]
    },
    "text": {
      "x-title": "Text Input",
      "default": "What's in this image?",
      "x-displayOptions": {
        "show": {
          "operation": [
            "analyze"
          ],
          "resource": [
            "image"
          ]
        }
      },
      "type": "string",
      "x-rows": 2
    },
    "inputType": {
      "x-title": "Input Type",
      "default": "binary",
      "x-displayOptions": {
        "show": {
          "operation": [
            "analyze"
          ],
          "resource": [
            "image"
          ]
        }
      },
      "type": "string",
      "enum": [
        "binary",
        "url"
      ],
      "x-enumNames": [
        "Binary File(s)",
        "Image URL(s)"
      ]
    },
    "binaryPropertyName": {
      "x-title": "Input Data Field Name(s)",
      "description": "Name of the binary field(s) which contains the image(s), separate multiple field names with commas",
      "default": "data",
      "x-displayOptions": {
        "show": {
          "inputType": [
            "binary"
          ],
          "operation": [
            "analyze"
          ],
          "resource": [
            "image"
          ]
        }
      },
      "type": "string"
    },
    "imageUrls": {
      "x-title": "URL(s)",
      "description": "URL(s) of the image(s) to analyze, multiple URLs can be added separated by comma",
      "default": "",
      "x-displayOptions": {
        "show": {
          "inputType": [
            "url"
          ],
          "operation": [
            "analyze"
          ],
          "resource": [
            "image"
          ]
        }
      },
      "type": "string"
    },
    "simplify": {
      "x-title": "Simplify Output",
      "description": "Whether to simplify the response or not",
      "default": true,
      "x-displayOptions": {
        "show": {
          "operation": [
            "message"
          ],
          "resource": [
            "text"
          ]
        }
      },
      "type": "boolean"
    },
    "options": {
      "x-title": "Options",
      "default": {},
      "x-displayOptions": {
        "show": {
          "operation": [
            "message"
          ],
          "resource": [
            "text"
          ]
        }
      },
      "type": "object",
      "properties": {
        "system": {
          "x-title": "System Message",
          "description": "System message to set the context for the conversation",
          "default": "",
          "type": "string",
          "x-rows": 2
        },
        "temperature": {
          "x-title": "Temperature",
          "description": "Controls randomness in responses. Lower values make output more focused.",
          "default": 0.8,
          "type": "number",
          "minimum": 0,
          "maximum": 2,
          "x-precision": 2
        },
        "top_p": {
          "x-title": "Output Randomness (Top P)",
          "description": "The maximum cumulative probability of tokens to consider when sampling",
          "default": 0.7,
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "x-precision": 1
        },
        "top_k": {
          "x-title": "Top K",
          "description": "Controls diversity by limiting the number of top tokens to consider",
          "default": 40,
          "type": "number",
          "minimum": 1
        },
        "num_predict": {
          "x-title": "Max Tokens",
          "description": "Maximum number of tokens to generate in the completion",
          "default": 1024,
          "type": "number",
          "minimum": 1,
          "x-precision": 0
        },
        "frequency_penalty": {
          "x-title": "Frequency Penalty",
          "description": "Adjusts the penalty for tokens that have already appeared in the generated text. Higher values discourage repetition.",
          "default": 0,
          "type": "number",
          "minimum": 0,
          "x-precision": 2
        },
        "presence_penalty": {
          "x-title": "Presence Penalty",
          "description": "Adjusts the penalty for tokens based on their presence in the generated text so far. Positive values penalize tokens that have already appeared, encouraging diversity.",
          "default": 0,
          "type": "number",
          "x-precision": 2
        },
        "repeat_penalty": {
          "x-title": "Repetition Penalty",
          "description": "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient.",
          "default": 1.1,
          "type": "number",
          "minimum": 0,
          "x-precision": 2
        },
        "num_ctx": {
          "x-title": "Context Length",
          "description": "Sets the size of the context window used to generate the next token",
          "default": 4096,
          "type": "number",
          "minimum": 1,
          "x-precision": 0
        },
        "repeat_last_n": {
          "x-title": "Repeat Last N",
          "description": "Sets how far back for the model to look back to prevent repetition. (0 = disabled, -1 = num_ctx).",
          "default": 64,
          "type": "number",
          "minimum": -1,
          "x-precision": 0
        },
        "min_p": {
          "x-title": "Min P",
          "description": "Alternative to the top_p, and aims to ensure a balance of quality and variety. The parameter p represents the minimum probability for a token to be considered, relative to the probability of the most likely token.",
          "default": 0,
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "x-precision": 3
        },
        "seed": {
          "x-title": "Seed",
          "description": "Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt.",
          "default": 0,
          "type": "number",
          "minimum": 0,
          "x-precision": 0
        },
        "stop": {
          "x-title": "Stop Sequences",
          "description": "Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Separate multiple patterns with commas",
          "default": "",
          "type": "string"
        },
        "keep_alive": {
          "x-title": "Keep Alive",
          "description": "Specifies the duration to keep the loaded model in memory after use. Format: 1h30m (1 hour 30 minutes).",
          "default": "5m",
          "type": "string"
        },
        "low_vram": {
          "x-title": "Low VRAM Mode",
          "description": "Whether to activate low VRAM mode, which reduces memory usage at the cost of slower generation speed. Useful for GPUs with limited memory.",
          "default": false,
          "type": "boolean"
        },
        "main_gpu": {
          "x-title": "Main GPU ID",
          "description": "Specifies the ID of the GPU to use for the main computation. Only change this if you have multiple GPUs.",
          "default": 0,
          "type": "number",
          "minimum": 0,
          "x-precision": 0
        },
        "num_batch": {
          "x-title": "Context Batch Size",
          "description": "Sets the batch size for prompt processing. Larger batch sizes may improve generation speed but increase memory usage.",
          "default": 512,
          "type": "number",
          "minimum": 1,
          "x-precision": 0
        },
        "num_gpu": {
          "x-title": "Number of GPUs",
          "description": "Specifies the number of GPUs to use for parallel processing. Set to -1 for auto-detection.",
          "default": -1,
          "type": "number",
          "minimum": -1,
          "x-precision": 0
        },
        "num_thread": {
          "x-title": "Number of CPU Threads",
          "description": "Specifies the number of CPU threads to use for processing. Set to 0 for auto-detection.",
          "default": 0,
          "type": "number",
          "minimum": 0,
          "x-precision": 0
        },
        "penalize_newline": {
          "x-title": "Penalize Newlines",
          "description": "Whether the model will be less likely to generate newline characters, encouraging longer continuous sequences of text",
          "default": true,
          "type": "boolean"
        },
        "use_mlock": {
          "x-title": "Use Memory Locking",
          "description": "Whether to lock the model in memory to prevent swapping. This can improve performance but requires sufficient available memory.",
          "default": false,
          "type": "boolean"
        },
        "use_mmap": {
          "x-title": "Use Memory Mapping",
          "description": "Whether to use memory mapping for loading the model. This can reduce memory usage but may impact performance.",
          "default": true,
          "type": "boolean"
        },
        "vocab_only": {
          "x-title": "Load Vocabulary Only",
          "description": "Whether to only load the model vocabulary without the weights. Useful for quickly testing tokenization.",
          "default": false,
          "type": "boolean"
        },
        "format": {
          "x-title": "Output Format",
          "description": "Specifies the format of the API response",
          "default": "",
          "type": "string",
          "enum": [
            "",
            "json"
          ],
          "x-enumNames": [
            "Default",
            "JSON"
          ]
        }
      }
    },
    "messages": {
      "x-title": "Messages",
      "default": {
        "values": [
          {
            "content": "",
            "role": "user"
          }
        ]
      },
      "x-displayOptions": {
        "show": {
          "operation": [
            "message"
          ],
          "resource": [
            "text"
          ]
        }
      },
      "type": "object",
      "properties": {
        "values": {
          "x-title": "Values",
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "content": {
                "x-title": "Content",
                "description": "The content of the message to be sent",
                "default": "",
                "type": "string",
                "x-rows": 2
              },
              "role": {
                "x-title": "Role",
                "description": "The role of this message in the conversation",
                "default": "user",
                "type": "string",
                "enum": [
                  "user",
                  "assistant"
                ],
                "x-enumNames": [
                  "User",
                  "Assistant"
                ],
                "x-enumDescriptions": [
                  "Message from the user",
                  "Response from the assistant (for conversation history)"
                ]
              }
            }
          }
        }
      }
    }
  },
  "x-subtitle": "={{ $parameter[\"operation\"] + \": \" + $parameter[\"resource\"] }}",
  "x-icon": "file:ollama.svg",
  "x-inputs": "={{\n\t\t(() => {\n\t\t\tconst resource = $parameter.resource;\n\t  \tconst operation = $parameter.operation;\n\t\t\tif (resource === 'text' && operation === 'message') {\n\t\t\t\treturn [{ type: 'main' }, { type: 'ai_tool', displayName: 'Tools' }];\n\t\t\t}\n\n\t\t\treturn ['main'];\n\t\t})()\n\t}}",
  "x-outputs": [
    "main"
  ],
  "x-credentials": [
    {
      "name": "ollamaApi",
      "required": true
    }
  ]
}
